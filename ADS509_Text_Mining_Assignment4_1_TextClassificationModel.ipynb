{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmmaCOo/Assignment-4.1-Text_Classification/blob/main/ADS509_Text_Mining_Assignment4_1_TextClassificationModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**ADS 509 Module 4: Assignment 4.1: Text Classification Model**\n",
        "\n",
        "###**Emma Oo**\n",
        "\n",
        "###09/26/2022"
      ],
      "metadata": {
        "id": "Dw7wdSp6jKk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment, we use NaÃ¯ve Bayes (NB) for its two greatest strengths:\n",
        "\n",
        "Exploration of a data set.\n",
        "\n",
        "Classification of new data based on training data.\n",
        "\n",
        "Instruction Repo Link:\n",
        "\n",
        "https://github.com/37chandler/tm-nb-conventions/blob/main/Political%20Naive%20Bayes.ipynb"
      ],
      "metadata": {
        "id": "q7e6GOJAjXMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAcvUNFb9sdf",
        "outputId": "aaa2213d-c68d-46cc-8e1a-5c329d32fa1d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji==1.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP2PfnSUgmlF",
        "outputId": "af95659e-a4c1-4b4a-e22a-62f274924a1d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji==1.7 in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYR48EAlieDs",
        "outputId": "93cebdb8-a80d-419e-aa0d-62142614bc92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "import nltk\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from string import punctuation\n",
        "\n",
        "import os\n",
        "import re\n",
        "import emoji\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from wordcloud import WordCloud \n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feel free to include your text patterns functions\n",
        "#from text_functions_solutions import clean_tokenize, get_patterns\n",
        "\n",
        "\n",
        "# Some punctuation variations\n",
        "punctuation = set(punctuation) # speeds up comparison\n",
        "punctuation.add('â€™')  # manual add the punctuation symbols that weren't removed from convention_db after trial runs\n",
        "punctuation.add('\" \"') # manual add the punctuation symbols that weren't removed from convention_db after trial runs\n",
        "tw_punct = punctuation\n",
        "\n",
        "# Stopwords\n",
        "#sw = stopwords.words(\"english\")\n",
        "\n",
        "# Two useful regex\n",
        "whitespace_pattern = re.compile(r\"\\s+\")\n",
        "hashtag_pattern = re.compile(r\"^#[0-9a-zA-Z]+\")\n",
        "\n",
        "# It's handy to have a full set of emojis\n",
        "all_language_emojis = set()\n",
        "\n",
        "for country in emoji.UNICODE_EMOJI : \n",
        "    for em in emoji.UNICODE_EMOJI[country] : \n",
        "        all_language_emojis.add(em)\n",
        "\n",
        "\n",
        "def is_emoji(s):\n",
        "    return(s in all_language_emojis)\n",
        "\n",
        "def contains_emoji(s):\n",
        "    \n",
        "    s = str(s)\n",
        "    emojis = [ch for ch in s if is_emoji(ch)]\n",
        "\n",
        "    return(len(emojis) > 0)\n",
        "\n",
        "#Remove Stopwords\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "def remove_stop(tokens) :\n",
        "  return[t for t in tokens if t not in stopwords]\n",
        "\n",
        "#Remove Punctuation\n",
        "def remove_punctuation(text, punct_set=tw_punct) : \n",
        "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
        "\n",
        "\n",
        "#Tokenization while keeping # and emojis\n",
        "RE_TOKEN = re.compile(r\"\"\"\n",
        "                   ( [#]?[@\\w'â€™\\.\\-\\:]*\\w     # words, hashtags and email addresses\n",
        "                   | [:;<]\\-?[\\)\\(3]          # coarse pattern for basic text emojis\n",
        "                   | [\\U0001F100-\\U0001FFFF]  # coarse code range for unicode emojis\n",
        "                   )\n",
        "                  \"\"\", re.VERBOSE)\n",
        "def tokenize(text) : \n",
        "  return text.split()\n",
        "\n",
        "\n",
        "#Define pipeline function\n",
        "pipeline = [str.lower, remove_punctuation, tokenize, remove_stop]\n",
        "def prepare(text, pipeline) : \n",
        "    tokens = str(text)\n",
        "    \n",
        "    for transform in pipeline : \n",
        "        tokens = transform(tokens)\n",
        "        \n",
        "    return(tokens)\n",
        "  \n",
        "my_pipeline = [str.lower, remove_punctuation, tokenize, remove_stop]\n"
      ],
      "metadata": {
        "id": "N9ak_Ojhuuj2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (tw_punct) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODHnIju7anbq",
        "outputId": "9da29c9e-98fd-41ef-ebfb-2e8adee3dcd0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'~', '/', '@', '`', '(', '_', 'â€™', ',', ':', '[', '{', '+', '!', ')', '%', '^', '.', '\"', '$', ';', '-', \"'\", '=', '\" \"', '<', '}', '?', ']', '|', '>', '*', '#', '&', '\\\\'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#connect to SQL DB\n",
        "convention_db = sqlite3.connect(\"/content/drive/MyDrive/2020_Conventions.db\")\n",
        "#Execute the SQL query\n",
        "convention_cur = convention_db.cursor()"
      ],
      "metadata": {
        "id": "KtVFJHD4l4bE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Part 1: Exploratory Naive Bayes**\n",
        "\n",
        "\n",
        "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text for each party and prepare it for use in Naive Bayes."
      ],
      "metadata": {
        "id": "IksneK2XmP09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convention_data = []\n",
        "raw_text =[]\n",
        "\n",
        "# fill this list up with items that are themselves lists. The \n",
        "# first element in the sublist should be the cleaned and tokenized\n",
        "# text in a single string. The second element should be the party. \n",
        "\n",
        "query_results = convention_cur.execute(\n",
        "                            '''\n",
        "                            SELECT text, party   \n",
        "                            FROM conventions\n",
        "                            ''')\n",
        "\n",
        "for row in query_results :\n",
        "    # store the results in convention_data\n",
        "    raw_text = [row[0]]  #text column is at row[0]\n",
        "    clean_text = prepare(raw_text, pipeline = my_pipeline)  #apply data cleaning pipeline on raw_text\n",
        "    string_clean_text = \" \".join(clean_text) #create a cleaned and tokenized text in a SINGLE STRING\n",
        "    clean_data = [string_clean_text, row[1]] #combine cleaned tokenized string and party column\n",
        "    convention_data.append(clean_data)    \n",
        "\n"
      ],
      "metadata": {
        "id": "SqPh1Y9ImThD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at some random entries and see if they look right.\n",
        "\n"
      ],
      "metadata": {
        "id": "U5EgfCJM__uL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.choices(convention_data,k=10)"
      ],
      "metadata": {
        "id": "b8xU7ln5_9C5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc40db6-c859-4e78-d2f6-2f80eceb5dc7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['joe helped bring us back recession 2009 barack obama joe biden started worst economy since great depression done delivered six straight years job growth',\n",
              "  'Democratic'],\n",
              " ['president trump continues place strong women significant positions throughout administration campaign far president us history',\n",
              "  'Republican'],\n",
              " ['see theres another part story part ran office part served congress part worked joe biden barack obama make sure kids grandkids theyre dependents stay parents health insurance theyre 26 got done yes big effing deal thats america know thats america love thats america joe biden kamala harris white house nation plans nation builds nation builds back say home nation builds back better wisconsin state motto one word forward november lets move forward never look back thank',\n",
              "  'Democratic'],\n",
              " ['okay dont know grandfather', 'Democratic'],\n",
              " ['led become lawyer district attorney attorney general united states senator every step way ive guided words spoke first time stood courtroom kamala harris people fought children survivors sexual assault fought transnational criminal organizations took biggest banks help take one biggest profit colleges know predator see one mother taught service others gives life purpose meaning oh wish tonight know shes looking keep thinking 25yearold indian woman five feet tall gave birth kaiser hospital oakland california day probably could never imagined would standing speaking words',\n",
              "  'Democratic'],\n",
              " ['almost four years ago went election day completely underestimated despite said year know americans go polls behalf families economy national security childrens future vote ideas partisan vote common sense vote goals hopes believe believe need husbands leadership ever order bring us back greatest economy strongest country ever known god bless families god bless united states america related transcripts iowa gov kim reynolds press conference transcript september 16 â€¢ 46 mins ago press secretary kayleigh mcenany white house press conference transcript september 16 â€¢ 58 mins ago doj press conference transcript september 16 charges 5 chinese nationals â€¢ 2 hours ago rnc night 2 rnc night 2 first lady melania trump secretary state mike pompeo eric trump speak second night republican national convention watch speeches live posted npr tuesday august 25 2020 stay updated get weekly digest weeks important transcripts inbox news without news please enable javascript browser complete form email kind transcripts want read submit transcription overview works faq mobile app captions overview works faq caption converter subtitles translation overview certified translation business translation faq request quote company press careers freelancers blog api get touch 222 kearny st 8th floor san francisco ca 94108 contact us 8883690701 supportrevcom Â© revcom reviews terms privacy stay updated get weekly digest weeks important transcripts inbox news without news please enable javascript browser complete form email kind transcripts want read submit stay updated get weekly digest weeks important transcripts inbox news without news please enable javascript browser complete form email kind transcripts want read submit stay updated get weekly digest weeks important transcripts inbox news without news please enable javascript browser complete form email kind transcripts want read submit',\n",
              "  'Republican'],\n",
              " ['â€œdefund policeâ€ rallying cry new radical democrat party joe biden takes maintain order keep children safe neighborhoods schools restore american way life cannot dare dream biggest dreams children consumed worry safety families president trump law order president borders backyards president trump keep america safe president trump keep america prosperous president trump keep america america youre watching tonight wrestling vote november 3rd implore tune distorted news biased commentary hear straight someone knows wasnt born trump im south raised carolina girl went public schools worked way state university',\n",
              "  'Republican'],\n",
              " ['absolutely entirely', 'Republican'],\n",
              " ['good evening begin want send special message everyone whos affected hurricane laura hearts president continue support every step way like americans always nation come together help rebuild homes businesses communities stronger resilient ever four years ago introduced builder entrepreneur outsider peoples nominee president united states tonight stand proud daughter peoples president commander chief champion american worker defender common sense voice forgotten men women country president father donald j trump',\n",
              "  'Republican'],\n",
              " ['foreign domestic', 'Republican']]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least word_cutoff times. Here's the code to test that if you want it."
      ],
      "metadata": {
        "id": "P5rl9274JFaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_cutoff = 5\n",
        "\n",
        "tokens = [w for t, p in convention_data for w in t.split()]\n",
        "\n",
        "word_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "feature_words = set()\n",
        "\n",
        "for word, count in word_dist.items() :\n",
        "    if count > word_cutoff :\n",
        "        feature_words.add(word)\n",
        "        \n",
        "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
      ],
      "metadata": {
        "id": "2XM30G3_JGQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca57cf02-18cb-40b2-84fe-861e26755e3c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With a word cutoff of 5, we have 2387 as features in the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_dist  #let's look at some freq distribution of word"
      ],
      "metadata": {
        "id": "kL1tjiaTbdiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b95e0f4-2a53-4a01-c86d-fa5582320eb5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'president': 1101, 'joe': 778, 'us': 745, 'trump': 708, 'america': 679, 'biden': 671, 'people': 608, 'country': 506, 'american': 462, 'one': 430, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_features(text,fw) :\n",
        "    \"\"\"Given some text, this returns a dictionary holding the\n",
        "       feature words.\n",
        "       \n",
        "       Args: \n",
        "            * text: a piece of text in a continuous string. Assumes\n",
        "            text has been cleaned and case folded.  #convention_data[0]\n",
        "            * fw: the *feature words* that we're considering. A word \n",
        "            in `text` must be in fw in order to be returned. This \n",
        "            prevents us from considering very rarely occurring words. #feature_words\n",
        "        \n",
        "       Returns: \n",
        "            A dictionary with the words in `text` that appear in `fw`. \n",
        "            Words are only counted once. \n",
        "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
        "            then this would return a dictionary of \n",
        "            {'quick' : True,\n",
        "             'fox' :    True}\n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    # Your code here\n",
        "    ret_dict = dict()\n",
        "    for i in text.split():\n",
        "        if i in fw:\n",
        "            ret_dict[i] = True\n",
        "    return(ret_dict)"
      ],
      "metadata": {
        "id": "_MBYQj-rJqNM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assert to check if the function has any bug\n",
        "assert(len(feature_words)>0)\n",
        "assert(conv_features(\"donald is the president\",feature_words)==\n",
        "       {'donald':True,'president':True})\n",
        "assert(conv_features(\"people are american in america\",feature_words)==\n",
        "                     {'america':True,'american':True,\"people\":True})\n"
      ],
      "metadata": {
        "id": "UQNRWl-fbAQV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory."
      ],
      "metadata": {
        "id": "MyGakXy5VmhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#apply conv_feature function onto convention_data set\n",
        "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
      ],
      "metadata": {
        "id": "fpzWP2bPW-eS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split test_size=500\n",
        "random.seed(20220507)\n",
        "random.shuffle(featuresets)\n",
        "\n",
        "test_size = 500"
      ],
      "metadata": {
        "id": "Tour4IyShNIw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train, test for NB classifier model and print accuracy\n",
        "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "metadata": {
        "id": "Tx9SEqrZhQEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6934d412-1f96-4ab1-f03c-8104fa32377a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print top 25 most informative features\n",
        "classifier.show_most_informative_features(25)"
      ],
      "metadata": {
        "id": "sQZW84sphTKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16d2f88-5008-4c48-f236-7ad1a269c314"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "                   china = True           Republ : Democr =     25.8 : 1.0\n",
            "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
            "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
            "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
            "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
            "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
            "                supports = True           Republ : Democr =     17.1 : 1.0\n",
            "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
            "                   media = True           Republ : Democr =     14.9 : 1.0\n",
            "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
            "               countries = True           Republ : Democr =     13.0 : 1.0\n",
            "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
            "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
            "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
            "                religion = True           Republ : Democr =     13.0 : 1.0\n",
            "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
            "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
            "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
            "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
            "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
            "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
            "              department = True           Republ : Democr =     10.9 : 1.0\n",
            "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
            "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
            "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
        "\n",
        "###**My Observations**\n",
        "\n",
        "The ratio of the Republican and Democratic are displayed for all the top feature tokens. For example, for the token 'china', the republic to democratic ratio is 25.8:1.00. Majority of the words from the top 25 features were used by Republicans such as 'china', 'enforcement', 'destroy', 'freedom' etc.  The only two words that democractic use more than Republicans are 'vote' and 'climate.' This study reveals the subjects and topics that each party liked to discuss and raised their concern about. \n"
      ],
      "metadata": {
        "id": "aWhDyqvIi2nn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Part 2: Classifying Congressional Tweets**\n",
        "\n",
        "\n",
        "In this part we **apply the classifer we just built** to a set of tweets by people running for congress in 2018. These tweets are stored in the database congressional_data.db. That DB is funky, so I'll give you the query I used to pull out the tweets. Note that this DB has some big tables and is unindexed, so the query takes a minute or two to run on my machine."
      ],
      "metadata": {
        "id": "QcjmyMfhsL4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cong_db = sqlite3.connect(\"/content/drive/MyDrive/congressional_data.db\")\n",
        "cong_cur = cong_db.cursor()"
      ],
      "metadata": {
        "id": "jXVoysSlt2-R"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = cong_cur.execute(\n",
        "        '''\n",
        "           SELECT DISTINCT \n",
        "                  cd.candidate, \n",
        "                  cd.party,\n",
        "                  tw.tweet_text\n",
        "           FROM candidate_data cd \n",
        "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
        "               AND cd.candidate == tw.candidate \n",
        "               AND cd.district == tw.district\n",
        "           WHERE cd.party in ('Republican','Democratic') \n",
        "               AND tw.tweet_text NOT LIKE '%RT%'\n",
        "        ''')\n",
        "\n",
        "results = list(results) # Just to store it, since the query is time consuming"
      ],
      "metadata": {
        "id": "fpBvV7_91gsq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's look at result data frame to get an idea of what the result data looks like\n",
        "df = pd.DataFrame(results)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "s2LV7PtKTtzG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a5bd8713-6643-4f3c-ca42-6959ea7b3db3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0           1                                                  2\n",
              "0  Mo Brooks  Republican  b'\"Brooks Joins Alabama Delegation in Voting A...\n",
              "1  Mo Brooks  Republican  b'\"Brooks: I Do Not Support America Raising, T...\n",
              "2  Mo Brooks  Republican  b'\"Brooks: Senate Democrats Allowing President...\n",
              "3  Mo Brooks  Republican  b'\"NASA on the Square\" event this Sat. 11AM \\x...\n",
              "4  Mo Brooks  Republican  b'\"Rep. Mo Brooks: NDAA Amnesty Amendment \\xe2..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-217c382e-19de-4531-b97c-08945f965a40\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mo Brooks</td>\n",
              "      <td>Republican</td>\n",
              "      <td>b'\"Brooks Joins Alabama Delegation in Voting A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mo Brooks</td>\n",
              "      <td>Republican</td>\n",
              "      <td>b'\"Brooks: I Do Not Support America Raising, T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mo Brooks</td>\n",
              "      <td>Republican</td>\n",
              "      <td>b'\"Brooks: Senate Democrats Allowing President...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mo Brooks</td>\n",
              "      <td>Republican</td>\n",
              "      <td>b'\"NASA on the Square\" event this Sat. 11AM \\x...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mo Brooks</td>\n",
              "      <td>Republican</td>\n",
              "      <td>b'\"Rep. Mo Brooks: NDAA Amnesty Amendment \\xe2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-217c382e-19de-4531-b97c-08945f965a40')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-217c382e-19de-4531-b97c-08945f965a40 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-217c382e-19de-4531-b97c-08945f965a40');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_data = []\n",
        "raw_tweet = []\n",
        "\n",
        "results = cong_cur.execute(\n",
        "        '''\n",
        "           SELECT DISTINCT \n",
        "                  cd.candidate, \n",
        "                  cd.party,\n",
        "                  tw.tweet_text\n",
        "           FROM candidate_data cd \n",
        "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
        "               AND cd.candidate == tw.candidate \n",
        "               AND cd.district == tw.district\n",
        "           WHERE cd.party in ('Republican','Democratic') \n",
        "               AND tw.tweet_text NOT LIKE '%RT%'\n",
        "        ''')\n",
        "\n",
        "for row in results:\n",
        "  raw_tweet = [row[2].decode('utf-8')]   # select text column (row[2]) and decode the b symbols in front of the text\n",
        "  clean_tweet = prepare(raw_tweet, pipeline = my_pipeline)\n",
        "  string_clean_tweet = \" \".join(clean_tweet)\n",
        "  clean_tweet_data = [string_clean_tweet,row[1]]  #pull only cleaned text and party\n",
        "  tweet_data.append(clean_tweet_data)\n",
        "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
        "# Note that this may take a bit of time, since we have a lot of tweets."
      ],
      "metadata": {
        "id": "RvtUhHl2Qf2H"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
      ],
      "metadata": {
        "id": "aPdje6_FWl8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.choices(tweet_data,k=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bv_x8NV8pAX",
        "outputId": "7f51a22c-adb1-4d8f-826e-b088a73afdea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['good morning amjalexjohnson', 'Democratic'],\n",
              " ['rt alexckaufman top democrats repdonbeyer rep gerryconnolly ask epas busy inspector general open investigation intâ€¦',\n",
              "  'Democratic'],\n",
              " ['rt swingleftca10 youngest canvasser day nico ca10 joshuaharder swingleft httpstco1zgrqliyfd',\n",
              "  'Democratic'],\n",
              " ['patients ask federal government permission save lives great see righttotry signed law congratulations one biggest champions state rep nickzerwas able white house signing ceremony',\n",
              "  'Republican'],\n",
              " ['join markreardonkmox yesterday discuss taxreform important economy amp middleincome families also collected friendly bet goraiders httpstcov8okl963s5 httpstcoqqavvyighk',\n",
              "  'Republican'],\n",
              " ['focus kind america want friends neighbors children grandchildren world applaud rep joe kennedy focusing positive vision future',\n",
              "  'Democratic'],\n",
              " ['im happy push muchneeded work beltrami island state forest public use areas outdoors huge part minnesota life atv snowmobile access important recreation economy seventhnnhttpstcojmcbufuayl',\n",
              "  'Democratic'],\n",
              " ['im live cbakershow kfabnews httpstco9cdyftsu7o', 'Republican'],\n",
              " ['support supporting grandparents raising grandchildren act ive seen many elderly patients raising young children must address ways help stepped raise grandchildren even already difficult circumstances httpstcow4zzjtufyg',\n",
              "  'Democratic'],\n",
              " ['6 bills considering today touch spectrum issues driving opioidepidemic',\n",
              "  'Republican']]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(20201014)\n",
        "tweet_data_sample = random.choices(tweet_data,k=10)"
      ],
      "metadata": {
        "id": "QOCMgaPtWmhp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tweet, party in tweet_data_sample :\n",
        "    estimated_party = classifier.classify(conv_features(tweet, feature_words))  #apply NB classifier on twitter_data\n",
        "    # Fill in the right-hand side above with code that estimates the actual party\n",
        "    \n",
        "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
        "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "s6aL99WqWr1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc86fd64-3de3-4cb3-f7e3-d1fa922c7f68"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's our (cleaned) tweet: mass shooting las vegas horrific act violence victims families thoughts prayers\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: early morning traveltuesday leaving ok02 dc httptcoigknci79e7\n",
            "Actual party is Republican and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: moderates iraq amp syria civilians weve enemies sides conflict assist either\n",
            "Actual party is Republican and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: rt natsecaction 200 national security veterans demanding answers release confidential national security questionnaâ€¦\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: ðŸ’¯ buildthatwall httpstcohyb6jcw5ea\n",
            "Actual party is Republican and our classifer says Democratic.\n",
            "\n",
            "Here's our (cleaned) tweet: glad attend g20 assure everyone could majority americans still stand traditional allies\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: cnn everyone wraps flag patriotism avoid discussion racism injustice kneeling honoring troops\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: applaud president trumps decision send national guard protect border congress support president including fully funding wall time stop playing politics national security united states fundthewall nationalguard\n",
            "Actual party is Republican and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: congress considers disaster relief spending year must include funding california fire relief listen remarks house floor httpstcompkbk1m7s5\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: proud support oss helped vanquish malevolent enemies countryâ€” free worldâ€” ever faced httpstco8vyiaviftt\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've looked at it some, let's score a bunch and see how we're doing.\n",
        "\n"
      ],
      "metadata": {
        "id": "Kez8NwN2bFqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary of counts by actual party and estimated party. \n",
        "# first key is actual, second is estimated\n",
        "parties = ['Republican','Democratic']\n",
        "results = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "for p in parties :\n",
        "    for p1 in parties :\n",
        "        results[p][p1] = 0\n",
        "\n",
        "\n",
        "num_to_score = 10000\n",
        "random.shuffle(tweet_data)\n",
        "\n",
        "\n",
        "for idx, tp in enumerate(tweet_data) :\n",
        "    tweet, party = tp    \n",
        "    # Now do the same thing as above, but we store the results rather\n",
        "    # than printing them. \n",
        "   \n",
        "    # get the estimated party\n",
        "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
        "    \n",
        "    results[party][estimated_party] += 1\n",
        "    \n",
        "    if idx > num_to_score : \n",
        "        break"
      ],
      "metadata": {
        "id": "9yK-sJ0XQ3FM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8eFCkdzIS5J",
        "outputId": "ca88d7e8-6b97-43f0-cf23-f53992a61d2a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>()>,\n",
              "            {'Republican': defaultdict(int,\n",
              "                         {'Republican': 3624, 'Democratic': 516}),\n",
              "             'Democratic': defaultdict(int,\n",
              "                         {'Republican': 5021, 'Democratic': 841})})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Reflections**\n",
        "\n",
        "Write a little about what you see in the results"
      ],
      "metadata": {
        "id": "YwBs_WWCbRqo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The NB classifier predicts majority as Republician over Democratic.  For the Republican tweets, the ratio of Republican to Democratic is 88%:12%.  For the Democratic, it is also 86% to 14%. The model seems biased towards the Republican class. It's possible that there's a class imbalance between Republican and Democratic with the lower tweet about Democratic. Thus, the NBC overlearn the Republican class and underfit the Democratic.  "
      ],
      "metadata": {
        "id": "xRl1NCM0KB1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert to html \n",
        "!jupyter nbconvert --to html /content/ADS509_Text_Mining_Assignment4_1_TextClassificationModel.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwkldL0BrAVB",
        "outputId": "f6c98511-0dd9-4841-a3a9-8c985e573b70"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/ADS509_Text_Mining_Assignment4_1_TextClassificationModel.ipynb to html\n",
            "[NbConvertApp] Writing 337791 bytes to /content/ADS509_Text_Mining_Assignment4_1_TextClassificationModel.html\n"
          ]
        }
      ]
    }
  ]
}